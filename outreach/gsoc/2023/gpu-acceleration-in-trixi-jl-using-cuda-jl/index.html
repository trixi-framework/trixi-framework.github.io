<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/basic.css"> <link rel=icon  href="/assets/favicon.ico"> <title>GSoC 2023: GPU acceleration in Trixi.jl using CUDA.jl</title> <header> <div class=blog-name ><a href="/"><img src="/assets/logo.png" width=100px ></a></div> <nav> <ul> <li><a href="/">Home</a> <li><a href="https://github.com/trixi-framework" target=_blank  rel="noopener noreferrer">Trixi on GitHub</a> </ul> </nav> </header> <div class=franklin-content ><h1 id=gsoc_2023_gpu_acceleration_in_trixijl_using_cudajl ><a href="#gsoc_2023_gpu_acceleration_in_trixijl_using_cudajl" class=header-anchor >GSoC 2023: GPU acceleration in Trixi.jl using CUDA.jl</a></h1> <ul> <li><p>Mentee: <a href="https://github.com/huiyuxie">Huiyu Xie</a></p> <li><p>Mentors: <a href="https://github.com/ranocha">Hendrik Ranocha</a> and <a href="https://github.com/sloede">Michael Schlottke-Lakemper</a></p> <li><p>Project Link: <a href="https://github.com/czha/TrixiGPU.jl/tree/legacy">https://github.com/huiyuxie/trixi&#95;cuda</a> &#40;moved to <a href="https://github.com/trixi-gpu/TrixiCUDA.jl">https://github.com/trixi-gpu/TrixiCUDA.jl</a>&#41;</p> </ul> <p>The goal of this GSoC project was to accelerate Trixi.jl using GPUs.</p> <p><strong>Table of contents</strong> <div class=franklin-toc ><ol><li><a href="#project_overview">Project Overview</a><li><a href="#key_highlights">Key Highlights</a><li><a href="#performance_benchmarks">Performance Benchmarks</a><li><a href="#future_work">Future Work</a><li><a href="#acknowledgements">Acknowledgements</a></ol></div></p> <h2 id=project_overview ><a href="#project_overview" class=header-anchor >Project Overview</a></h2> <p>The project was focused on enhancing the <a href="https://github.com/trixi-framework/Trixi.jl">Trixi.jl</a> numerical simulation framework, a prominent tool used for solving hyperbolic conservation laws within the Julia programming language. The primary aim was to introduce GPU support through <a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a> and essentially <a href="https://docs.nvidia.com/cuda">CUDA</a> to accelerate the discretization processes used in solving partial differential equations &#40;PDEs&#41;. This work was undertaken as part of the <a href="https://summerofcode.withgoogle.com/">Google Summer of Code 2023</a> program, and the progress is summarized below:</p> <ul> <li><p>GPU Implementation: The GPU implementations were prototyped using CUDA, starting with 1D equation kernels and gradually extending to more complex 2D and 3D equation kernels. These developments formed the backbone of the Discontinuous Galerkin Collocation Spectral Element Method &#40;DGSEM&#41; in the framework.</p> <li><p>Performance Benchmarks: A series of benchmarks were conducted on the developed CUDA kernels to assess their efficiency. These benchmarks demonstrated substantial performance enhancements through a strategic integration of various factors including data transfer, kernel architecture, and method characteristics.</p> <li><p>Acceleration Extension: The GPU support was not limited to basic kernels but was extended to more intricate methods within the framework. This included integration with the DG solver that allows meshes with simplex elements &#40;DGMulti&#41; and other summation-by-parts &#40;SBP&#41; schemes like Finite Differences &#40;FD&#41; and Continuous Galerkin Spectral Element Method &#40;CGSEM&#41; through the DGMulti solver.</p> </ul> <p>Please note that the third step was planned but remains incomplete due to time constraints and this step will be completed in the future if possible.</p> <h3 id=how_to_setup ><a href="#how_to_setup" class=header-anchor >How to Setup </a></h3> <p>This project was entirely set up and tested on Amazon Web Services &#40;AWS&#41;, and the instance type chosen was <a href="https://aws.amazon.com/ec2/instance-types/#Accelerated_Computing"><code>p3.2xlarge</code></a>. Here is the link to the specific information of both <a href="https://github.com/czha/TrixiGPU.jl/blob/legacy/docs/env_info.md">CPU and GPU</a> used for this project. Note that this project is reproducible by following the setup instructions provided link aboout <a href="https://github.com/czha/TrixiGPU.jl/blob/legacy/docs/project_setup.md">how to set up environment</a>. Also, for individuals without an Nvidia GPU but interested in experimenting with CUDA, here is a link detailing how to <a href="https://github.com/czha/TrixiGPU.jl/blob/legacy/docs/aws_gpu_setup.md">set up a cloud GPU on AWS</a>.</p> <h2 id=key_highlights ><a href="#key_highlights" class=header-anchor >Key Highlights</a></h2> <p>The overview of the project repository can be accessed through this <a href="https://github.com/czha/TrixiGPU.jl/blob/legacy/README.md">README.md</a> file. Here is a detailed description of the highlights of this project.</p> <h3 id=kernel_prototyping ><a href="#kernel_prototyping" class=header-anchor ><ol> <li><p>Kernel Prototyping</p> </ol> </a></h3> <p>Several function &#40;kernel&#41; naming rules were applied in the kernel prototyping process:</p> <ul> <li><p>The functions for GPU kernel parallel computing must end with <code>_kernel</code></p> <li><p>The functions for calling the GPU kernels must begin with <code>cuda_</code></p> </ul> <p>These rules make the whole structure of the GPU code consistent with the original CPU code. Also, the implementation essentially revolves around three points: </p> <ul> <li><p>Using custom kernel implementation instead of direct array &#40;and matrix&#41; operations through <code>CuArray</code> type</p> <li><p>Avoiding the use of conditional statement &#40;like <code>if/else</code> branches&#41; from the original CPU code</p> <li><p>Minimizing the number of GPU kernel calls within a certain function &#40;like <code>cuda_volume_integral&#33;</code>&#41;</p> </ul> <p>Based on these points, the work began with <code>dg_1d.jl</code>, and then extended to <code>dg_2d.jl</code> and <code>dg_3d.jl</code> under the <code>src/solvers/dgsem_tree</code> directory. The prototying mainly focused on the <code>rhs&#33;</code> functions that are called in the <code>semidiscretize</code> process. Besides, it is worthwhile to mention some caveats in this GPU prototyping process:</p> <ul> <li><p>CUDA.jl does not support dynamic array access and the use of other dynamic types inside kernels &#40;<a href="https://github.com/huiyuxie/trixi_cuda/issues/6">Issue #6</a>, <a href="https://github.com/huiyuxie/trixi_cuda/issues/8">Issue #8</a>, and <a href="https://github.com/huiyuxie/trixi_cuda/issues/11">Issue #11</a>&#41; </p> <li><p>GPU parallel computing can run into race conditions &#40;<a href="https://github.com/huiyuxie/trixi_cuda/issues/5">Issue #5</a>&#41;</p> <li><p>The <code>Float32</code> type can be promoted to <code>Float64</code> type in the GPU computing process &#40;<a href="https://github.com/huiyuxie/trixi_cuda/issues/3">Issue #3</a> and <a href="https://github.com/trixi-framework/Trixi.jl/pull/1604">PR #1604</a>&#41;</p> </ul> <h3 id=ol_start2_kernel_configuration ><a href="#ol_start2_kernel_configuration" class=header-anchor ><ol start=2 > <li><p>Kernel Configuration </p> </ol> </a></h3> <p>The GPU kernels were designed to be launched with the appropriate size of threads and blocks. The occupancy API <code>CUDA.launch_configuration</code> was used to create kernel configurator functions for 1D, 2D, and 3D kernels &#40;i.e., <code>configurator_1d</code>, <code>configurator_2d</code>, and <code>configurator_3d</code>&#41;. </p> <p>Specifically, in kernel configurator functions, <code>CUDA.launch_configuration</code> would first return a suggested number of threads for the compiled but not yet run kernel, and then the number of blocks would be computed through dividing the corresponding array size by the number of threads. </p> <p>Thus, in the process of calling a GPU kernel, the kernel is first compiled and then run based on the returned launching data from the configurator. For example, it is common to see code like </p> <pre><code class="Julia hljs">sample_kernel = <span class=hljs-meta >@cuda</span> launch = <span class=hljs-literal >false</span> sample_kernel!(arg1, arg2, arg3)
sample_kernel(arg1, arg2, arg3; configurator_1d(sample_kernel, size_arr)...) <span class=hljs-comment ># Similar for `configurator_2d` and configurator_3d`</span></code></pre> <p>in kernel calling functions. In this way, the GPU kernels are configured and launched with the intention of achieving maximal occupancy &#40;i.e., optimizing the utilization of GPU computing resources&#41;, potentially enhancing overall performance. However, it should be noted that the maximal occupancy cannot be reached in most cases.</p> <p>Also, this method of kernel configuration may not be optimal, considering that it may not be applicable to different GPU versions. Given that</p> <pre><code class="Julia hljs">julia&gt; attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_GRID_DIM_X) <span class=hljs-number >2147483647</span> 
julia&gt; attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK) <span class=hljs-number >1024</span></code></pre> <p>the kernel could be addressed in the crrent GPU version but may not in some other GPU versions &#40;as different GPU gives different attribute data like <code>CUDA.DEVICE_ATTRIBUTE_MAX_GRID_DIM_X</code> and <code>CUDA.DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK</code>&#41;. So it was suggested to introduce the use of a stride loop for the current GPU kernels.</p> <h3 id=ol_start3_kernel_optimization ><a href="#ol_start3_kernel_optimization" class=header-anchor ><ol start=3 > <li><p>Kernel Optimization</p> </ol> </a></h3> <p>Some work on kernel optimization has already been done during the process of kernel prototyping, such as avoiding the use of conditional branches and minimizing kernel calls. But the general work for kernel optimization has not yet been introdued &#40;so this part is somewhat related to the future work&#41;. </p> <p>In summary, the kernel optimization should be based on kernel benchmarks and kernel profiling, and here are some factors that can be considered to improve performance:</p> <ul> <li><p>Data Transfer: The process of data transfer from CPU to GPU &#40;and back&#41; mainly occurs in the <code>rhs&#33;</code> function when calling <code>semidiscretize</code>. Since <code>rhs&#33;</code> is called multiple times during the process of time integration, it would be more efficient to complete the data transfer before calling the <code>rhs&#33;</code> function.</p> <li><p>Stride Loop Tuning: The stride loop has not yet been introduced to the current GPU kernels. By applying stride loop tuning, the loop structure &#40;i.e., stride length&#41; can be modified to improve performance.</p> <li><p>Multi-GPU/Multi-Thread: The performance can be further improved if multiple GPUs or multiple threads are used.</p> </ul> <h2 id=performance_benchmarks ><a href="#performance_benchmarks" class=header-anchor >Performance Benchmarks</a></h2> <p>The performance benchmarks were conducted for both CPU and GPU on <code>Float64</code> and <code>Float32</code> types, respectively. The example files <code>elixir_advection_basic.jl</code>, <code>elixir_euler_ec.jl</code>, and <code>elixir_euler_source_terms.jl</code> were chosen from <code>tree_1d_dgsem</code>, <code>tree_2d_dgsem</code>, and <code>tree_3d_dgsem</code> under the <code>src/examples</code> directory. These examples were chosen because they are consistent in case of 1D, 2D, and 3D. Please note that all the examples have passed the accuracy tests and you can check them using this <a href="https://github.com/czha/TrixiGPU.jl/tree/legacy/src/examples">link to examples</a>.</p> <p>The benchmark results were archived in another file and please use this <a href="https://github.com/czha/TrixiGPU.jl/blob/legacy/docs/cuda_benchmark.md">link to benchmarks</a> to check them. Also note that the benchmarks were focuesd on the time integration part &#40;i.e., on <code>OrdinaryDiffEq.solve</code>&#41;, see a benchmark exmaple below </p> <pre><code class="Julia hljs"><span class=hljs-comment ># Run on CPU</span>
<span class=hljs-meta >@benchmark</span> <span class=hljs-keyword >begin</span>
    sol_cpu = OrdinaryDiffEq.solve(ode_cpu, BS3(), adaptive=<span class=hljs-literal >false</span>, dt=<span class=hljs-number >0.01</span>;
        abstol=<span class=hljs-number >1.0e-6</span>, reltol=<span class=hljs-number >1.0e-6</span>, ode_default_options()...)
<span class=hljs-keyword >end</span>

<span class=hljs-comment ># Run on GPU</span>
<span class=hljs-meta >@benchmark</span> <span class=hljs-keyword >begin</span>
    sol_gpu = OrdinaryDiffEq.solve(ode_gpu, BS3(), adaptive=<span class=hljs-literal >false</span>, dt=<span class=hljs-number >0.01</span>;
        abstol=<span class=hljs-number >1.0e-6</span>, reltol=<span class=hljs-number >1.0e-6</span>, ode_default_options()...)
<span class=hljs-keyword >end</span></code></pre> <p>From the benchmark results, it is shown that the GPU did not perform better than the CPU in general &#40;but there were some exceptions&#41;. Furthermore, the <code>Memory estimate</code> and <code>allocs estimate</code> statistics from the GPU are much larger than those from the CPU. This is probably due to the design that all the data transfer happens in the <code>rhs&#33;</code> function and thus the memory cost is extremely high when transferring data repeatedly between the CPU and GPU. </p> <p>In addition, the results indicate that the GPU performs better with 2D and 3D examples than with 1D examples. That is because GPUs are designed to handle a large number of parallel tasks, and 2D and 3D problems usually offer more parallelism compared to 1D problems. Essentially, the more data you can process simultaneously, the more efficiently you can utilize the GPU. 1D problems may not be complex enough to take full advantage of the GPU parallel processing capability.</p> <h2 id=future_work ><a href="#future_work" class=header-anchor >Future Work</a></h2> <p>The future work is listed here, ranging from specific to more general, from top to bottom:</p> <ol> <li><p>Resolve <a href="https://github.com/huiyuxie/trixi_cuda/issues/9">Issue #9</a> and <a href="https://github.com/huiyuxie/trixi_cuda/issues/11">Issue #11</a> &#40;and any upcoming issues&#41; </p> <li><p>Complete the prototype for the remaining kernels &#40;please refer to the Kernel to be Implemented from the <a href="https://github.com/czha/TrixiGPU.jl/blob/legacy/README.md">README.md</a> file&#41;.</p> <li><p>Update <a href="https://github.com/trixi-framework/Trixi.jl/pull/1604">PR #1604</a> and make it merged into the repository</p> <li><p>Optimize CUDA kernels to improve performance &#40;especially data transfer, please refer to the kernel optimization part&#41;</p> <li><p>Prototype the GPU kernels for other DG solvers &#40;for example, <code>DGMulti</code>, etc.&#41;</p> <li><p>Extend the single-GPU support to multi-GPU support &#40;similarly, from single-thread to multi-thread&#41;</p> <li><p>Broaden compatibility to other GPU types beyond Nvidia &#40;such as those from Apple, Intel, and AMD&#41;</p> </ol> <h2 id=acknowledgements ><a href="#acknowledgements" class=header-anchor >Acknowledgements</a></h2> <p>I would like to express my gratitude to Google, the Julia community, and my mentors &#40;<a href="https://github.com/ranocha">Hendrik Ranocha</a>, <a href="https://github.com/sloede">Michael Schlottke-Lakemper</a>, and <a href="https://github.com/jlchan">Jesse Chan</a>&#41; for this enriching experience during the Google Summer of Code 2023 program. This opportunity to participate, enhance my skills, and contribute to the advancement of Julia has been both challenging and rewarding.</p> <p>Special thanks go to my GSoC mentor <a href="https://github.com/ranocha">Hendrik Ranocha</a> &#40;@ranocha&#41; and another person from JuliaGPU <a href="https://github.com/maleadt"> Tim Besard</a> &#40;@maleadt, though he is not my mentor&#41;, whose guidance and support throughout our regular discussions have been instrumental in answering my questions and overcoming hurdles. The Julia community is incredibly welcoming and supportive, and I am proud to have been a part of this endeavor.</p> <p>I am filled with appreciation for this fantastic summer of learning and development, and I look forward to seeing the continued growth of Julia and the contributions of its vibrant community.</p> <div class=page-foot > <div class=copyright > &copy; <a href="https://github.com/trixi-framework/Trixi.jl/blob/main/AUTHORS.md" target=_blank  rel="noopener noreferrer">The Trixi Authors</a>. Last modified: February 04, 2025. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div>